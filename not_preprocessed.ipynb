{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=229000\n",
      "    Range : 0 ... 228999 =      0.000 ...  1831.992 secs\n",
      "Ready.\n",
      "[ 10124  17999  27124  36874  45499  56749  63749  71249  84374  89999\n",
      "  97499 107749 112124 117624 122374 127749 134624 143249 152374 168499\n",
      " 178124 187499 191749 196374 204749 212624 219374 228999]\n",
      "(80, 28, 3750, 32)\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 单位uV\n",
    "multi_personal_data = np.load('/Users/qiuzihan/Downloads/temp_code/data_all_4_47_ds.npy').transpose(0, 2, 1)*10**(-6)\n",
    "\n",
    "# mne.info创建\n",
    "info = mne.create_info(\n",
    "    ch_names=['Fp1', 'Fp2', 'Fz', 'F3', 'F4', 'F7', 'F8', 'FC1', 'FC2', 'FC5', 'FC6', 'Cz', 'C3', 'C4', 'T7', 'T8', 'CP1', 'CP2', 'CP5', 'CP6', 'Pz', 'P3', 'P4', 'P7', 'P8', 'PO3', 'PO4', 'Oz', 'O1', 'O2', 'A2', 'A1'], \n",
    "    ch_types=['eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg','eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg','eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg'], \n",
    "    sfreq=125\n",
    ")\n",
    "\n",
    "# 视频时长\n",
    "vedio_length = [81, 63, 73, 78, 69, 90, 56, 60, 105, 45, 60, 82, 35, 44, 38, 43, 55, 69, 73, 129, 77, 75, 34, 37, 67, 63, 54, 77]\n",
    "# 80个被试，28个视频片段，使用30s数据时长，32个eeg通道+1个时间戳用于检查（单位s，后续可删去）\n",
    "# used_data = np.zeros((80, 28, 30*125, 33))\n",
    "used_data = np.zeros((80, 28, 30*125, 32))\n",
    "\n",
    "# 创建trial时间戳\n",
    "data_index = np.zeros_like(vedio_length)\n",
    "for i in range(28):\n",
    "    data_index[i] = np.sum(vedio_length[:i+1])*125-1\n",
    "\n",
    "# 创建待使用数据\n",
    "for i in range(80):\n",
    "    subject_raw = mne.io.RawArray(multi_personal_data[i, :, :], info)\n",
    "    # 待填充预处理算法\n",
    "    df = subject_raw.to_data_frame()\n",
    "    for j in range(28):\n",
    "        # 要删去时间列，把下一行末尾由0：改为1：\n",
    "        # used_data[i, j, :, :] = df.values[data_index[j]-30*125:data_index[j], 0:]\n",
    "        used_data[i, j, :, :] = df.values[data_index[j]-30*125:data_index[j], 1:]\n",
    "\n",
    "print(data_index)\n",
    "print(used_data.shape)\n",
    "\n",
    "X_total = used_data\n",
    "y_total = np.array((0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 28, 3750, 32])\n",
      "torch.Size([80, 28])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X_total = torch.tensor(X_total, dtype=torch.float)\n",
    "y_total = torch.tensor(y_total).unsqueeze(0).repeat([X_total.shape[0], 1])\n",
    "print(X_total.shape)\n",
    "print(y_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'X':X_total, 'y':y_total}, 'data.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class Base_Dataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 data:torch.Tensor, \n",
    "                 label:torch.Tensor,\n",
    "                 channel_wise_normalize:bool = False):\n",
    "        if channel_wise_normalize:\n",
    "            data = F.normalize(data, dim=1)\n",
    "        self.data = data\n",
    "        self.labels = label\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.data is None or self.labels is None:\n",
    "            return 0\n",
    "        else:\n",
    "            return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class Onesec_Dataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 data:torch.Tensor, \n",
    "                 label:torch.Tensor,\n",
    "                 channel_wise_normalize:bool = False):\n",
    "        if channel_wise_normalize:\n",
    "            data = F.normalize(data, dim=1)\n",
    "        self.data = data\n",
    "        self.labels = label\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.data is None or self.labels is None:\n",
    "            return 0\n",
    "        else:\n",
    "            return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_total' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1043508/1834841488.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_total\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_total' is not defined"
     ]
    }
   ],
   "source": [
    "y_total[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_total_30 = y_total.repeat_interleave(30, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 840])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_total_30.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Onesec_Dataset(data=X_total.reshape(80*28, 3750, 32), label=y_total.reshape(80*28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=32, num_workers=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3750, 32])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 296])\n",
      "torch.Size([24, 9])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SeparableConv1d(nn.Module):\n",
    "    def __init__(self, c_in: int, c_out: int, kernel_size: tuple, padding: tuple = 0):\n",
    "        super().__init__()\n",
    "        self.c_in = c_in\n",
    "        self.c_out = c_out\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.depthwise_conv = nn.Conv1d(self.c_in, self.c_in, kernel_size=self.kernel_size,\n",
    "                                        padding=self.padding, groups=self.c_in)\n",
    "        self.conv1d_1x1 = nn.Conv1d(self.c_in, self.c_out, kernel_size=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        y = self.depthwise_conv(x)\n",
    "        y = self.conv1d_1x1(y)\n",
    "        return y\n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, nb_classes: int, Chans: int = 64, Samples: int = 128,\n",
    "                 dropoutRate: float = 0.25, kernLength: int = 63,\n",
    "                 F1:int = 8, D:int = 2):\n",
    "        super().__init__()\n",
    "        F2 = F1 * D\n",
    "        # Make kernel size and odd number\n",
    "        try:\n",
    "            assert kernLength % 2 != 0\n",
    "        except AssertionError:\n",
    "            raise ValueError(\"ERROR: kernLength must be odd number\")\n",
    "\n",
    "        # In: (B, Chans, Samples, 1)\n",
    "        # Out: (B, F1, Samples, 1)\n",
    "        self.conv1 = nn.Conv1d(Chans, F1, kernLength, padding=(kernLength // 2))\n",
    "        self.bn1 = nn.BatchNorm1d(F1) # (B, F1, Samples, 1)\n",
    "        # In: (B, F1, Samples, 1)\n",
    "        # Out: (B, F2, Samples - Chans + 1, 1)\n",
    "        self.conv2 = nn.Conv1d(F1, F2, Chans, groups=F1)\n",
    "        self.bn2 = nn.BatchNorm1d(F2) # (B, F2, Samples - Chans + 1, 1)\n",
    "        # In: (B, F2, Samples - Chans + 1, 1)\n",
    "        # Out: (B, F2, (Samples - Chans + 1) / 4, 1)\n",
    "        self.avg_pool = nn.AvgPool1d(4)\n",
    "        self.dropout = nn.Dropout(dropoutRate)\n",
    "\n",
    "        # In: (B, F2, (Samples - Chans + 1) / 4, 1)\n",
    "        # Out: (B, F2, (Samples - Chans + 1) / 4, 1)\n",
    "        self.conv3 = SeparableConv1d(F2, F2, kernel_size=15, padding=7)\n",
    "        self.bn3 = nn.BatchNorm1d(F2)\n",
    "        # In: (B, F2, (Samples - Chans + 1) / 4, 1)\n",
    "        # Out: (B, F2, (Samples - Chans + 1) / 32, 1)\n",
    "        self.avg_pool2 = nn.AvgPool1d(4)\n",
    "        # In: (B, F2 *  (Samples - Chans + 1) / 32)\n",
    "        self.fc = nn.Linear(F2 * ((Samples - Chans + 1) // 16), nb_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, output_feature=False):\n",
    "        # Block 1\n",
    "        # print(x.shape)\n",
    "        y1 = self.conv1(x)\n",
    "        y1 = self.bn1(y1)\n",
    "        y1 = self.conv2(y1)\n",
    "        # print(y1.shape)\n",
    "        y1 = F.relu(self.bn2(y1))\n",
    "        y1 = self.avg_pool(y1)\n",
    "        # print(y1.shape)\n",
    "        y1 = self.dropout(y1)\n",
    "        # Block 2\n",
    "        y2 = self.conv3(y1)\n",
    "        # print(y2.shape)\n",
    "        y2 = F.relu(self.bn3(y2))\n",
    "        y2 = self.avg_pool2(y2)\n",
    "        y2 = self.dropout(y2)\n",
    "        # print(y2.shape)\n",
    "        y2 = torch.flatten(y2, 1)\n",
    "        if output_feature:\n",
    "            return y2\n",
    "        else:\n",
    "            return self.fc(y2)\n",
    "\n",
    "    \n",
    "net = EEGNet(nb_classes=9, Chans=32, Samples=125, F1=4, D=2)\n",
    "input_tensor = batch[0].transpose(1,2).float()\n",
    "out_put = net(input_tensor[:, :, :125*5], output_feature=True)\n",
    "print(out_put.shape)\n",
    "out_put = net(input_tensor[:, :, :125], output_feature=False)\n",
    "print(out_put.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Built with Total Number of Trainable Parameters: 4845\n",
      "torch.Size([32, 64, 625, 1])\n",
      "torch.Size([32, 16, 16, 82])\n",
      "torch.Size([32, 4, 16, 82])\n",
      "torch.Size([32, 4, 8, 20])\n",
      "torch.Size([32, 640])\n",
      "torch.Size([32, 64, 125, 1])\n",
      "torch.Size([32, 16, 16, 20])\n",
      "torch.Size([32, 4, 16, 20])\n",
      "torch.Size([32, 4, 8, 5])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x160 and 40x9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m out_put \u001b[39m=\u001b[39m net2D(input_tensor[:, :, :\u001b[39m125\u001b[39m\u001b[39m*\u001b[39m\u001b[39m5\u001b[39m, :], output_feature\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     60\u001b[0m \u001b[39mprint\u001b[39m(out_put\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 61\u001b[0m out_put \u001b[39m=\u001b[39m net2D(input_tensor[:, :, :\u001b[39m125\u001b[39;49m, :], output_feature\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     62\u001b[0m \u001b[39mprint\u001b[39m(out_put\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/anaconda3/envs/exp/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [16], line 51\u001b[0m, in \u001b[0;36mEEGNet2D.forward\u001b[0;34m(self, x, output_feature)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m     50\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/exp/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/exp/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x160 and 40x9)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class EEGNet2D(nn.Module):\n",
    "    def __init__(self, dropout=0.25):\n",
    "        super(EEGNet2D, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 64, (1, 32), padding = 0)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(64, False)\n",
    "        # Layer 2\n",
    "        self.padding1 = nn.ZeroPad2d((16, 17, 0, 1))\n",
    "        self.conv2 = nn.Conv2d(1, 16, (2, 4), stride=(1, 2))\n",
    "        self.batchnorm2 = nn.BatchNorm2d(16, False)\n",
    "        self.pooling2 = nn.MaxPool2d(2, 4)\n",
    "        # Layer 3\n",
    "        self.padding2 = nn.ZeroPad2d((2, 1, 4, 3))\n",
    "        self.conv3 = nn.Conv2d(16, 4, (8, 4))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling3 = nn.MaxPool2d((2, 4))\n",
    "        self.fc1 = nn.Linear(160, 9)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, output_feature=False):\n",
    "        # Layer 1\n",
    "        bs = x.shape[0]\n",
    "        x = F.elu(self.conv1(x))\n",
    "        print(x.shape)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.dropout(x, self.dropout)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        # Layer 2\n",
    "        x = self.padding1(x)\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = F.dropout(x, self.dropout)\n",
    "        x = self.pooling2(x)\n",
    "        print(x.shape)\n",
    "        # Layer 3\n",
    "        x = self.padding2(x)\n",
    "        x = F.elu(self.conv3(x))\n",
    "        print(x.shape)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.dropout(x, self.dropout)\n",
    "        x = self.pooling3(x)\n",
    "        print(x.shape)\n",
    "        x = x.reshape(bs, -1)\n",
    "        if output_feature:\n",
    "            return x\n",
    "        else:\n",
    "            return self.fc1(x)\n",
    "\n",
    "net2D = EEGNet2D()\n",
    "\n",
    "total_params = sum(p.numel() for p in net2D.parameters() if p.requires_grad)\n",
    "print(\"Model Built with Total Number of Trainable Parameters: \" + str(total_params)) \n",
    "\n",
    "input_tensor = batch[0].float().unsqueeze(1)\n",
    "out_put = net2D(input_tensor[:, :, :125*5, :], output_feature=True)\n",
    "print(out_put.shape)\n",
    "out_put = net2D(input_tensor[:, :, :125, :], output_feature=False)\n",
    "print(out_put.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "\n",
    "class Contrastive_Dataset(Dataset):\n",
    "    \"\"\"实现正负样本选择匹配的Dataset, 方便contrastive loss计算\n",
    "    Args:\n",
    "        data: 原始数据，形状为（被试数，trail，采样频率*每段总时间，通道数）\n",
    "        seconds: 每段总时长，我们选取30s\n",
    "        sample_interval: 选择用于contrastive learning的片段长度，默认为5s\n",
    "        frequency: 采样频率，在本问题中为 125Hz\n",
    "        neg_number: 在计算contrastive loss时选取的参考数，最后计算contrastive loss时分母有 2*neg_number+1 项\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 data:torch.Tensor, # 80, 28, 3750, 32\n",
    "                 seconds:int = 30,\n",
    "                 sample_interval:int = 5,\n",
    "                 frequency:int = 125,\n",
    "                 neg_number:int = 10):\n",
    "        assert neg_number < 28, \"number of negtive references should be smaller than number of trails\"\n",
    "        assert sample_interval < 30, \"length of reference should be smaller than trail length\"\n",
    "        self.seconds = seconds\n",
    "        self.frequency = frequency\n",
    "        self.sample_interval = sample_interval\n",
    "        self.data = data\n",
    "        self.total_trial = self.data.shape[1]\n",
    "        self.neg_number = neg_number\n",
    "\n",
    "    def __getitem__(self, index): # index 为样本A\n",
    "        # 从总的 trail 数中 不重复地 选择neg_number+1个trial\n",
    "        ref_trails = random.sample(range(self.total_trial), k=self.neg_number+1)\n",
    "        # 将其中的1个作为正参考，如此实现避免了重复选择\n",
    "        pos_index = ref_trails[0]\n",
    "        # 随机在trial的30s中选取一段用于计算feature\n",
    "        interval = random.randint(0, self.seconds-self.sample_interval-1)\n",
    "        # 随机在所有被试样本中选取一个作为参考B\n",
    "        ref_sample = random.randint(0, self.data.shape[0]-1)\n",
    "        ref_sample = (ref_sample + 1)%self.data.shape[0] if ref_sample==index else ref_sample # 避免重复及索引超出范围\n",
    "        # 将样本A与样本B的用于计算contrastive loss分母部分组合\n",
    "        neg_samples = torch.cat((self.data[index, ref_trails[1:], interval*self.frequency:(interval+self.sample_interval)*self.frequency],\\\n",
    "            self.data[ref_sample, ref_trails, interval*self.frequency:(interval+self.sample_interval)*self.frequency]), dim=0)\n",
    "        # 返回样本A，样本B中的pos reference及neg reference\n",
    "        return self.data[index, pos_index, interval*self.frequency:(interval+self.sample_interval)*self.frequency],\\\n",
    "                self.data[ref_sample, pos_index, interval*self.frequency:(interval+self.sample_interval)*self.frequency],\\\n",
    "                    neg_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.data is None:\n",
    "            return 0\n",
    "        else:\n",
    "            return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "contra_dataset = Contrastive_Dataset(X_total)\n",
    "train_loader = DataLoader(dataset=contra_dataset, batch_size=24, num_workers=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 625, 32]) torch.Size([24, 625, 32]) torch.Size([24, 21, 625, 32])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    # 使用2D卷积的情况\n",
    "    bs, trials = batch[2].shape[0], batch[2].shape[1]\n",
    "    print(batch[0].shape, batch[1].shape, batch[2].shape) \n",
    "    # (bs, sample_interval*frequency, channel),  (bs, sample_interval*frequency, channel),  (bs, 2*neg_number+1, sample_interval*frequency, channel)\n",
    "    # 计算样本A中的用于比较的特征\n",
    "    test_feature = net2D(batch[0].float().unsqueeze(1), output_feature=True) # (bs, feature dim)\n",
    "    # 计算样本B中的pos参考特征\n",
    "    pos_ref = net2D(batch[1].float().unsqueeze(1), output_feature=True) # (bs, feature dim)\n",
    "    # 计算负向的参考特征\n",
    "    # 此处为了卷积计算，需要先将 (bs, 2*neg_number+1, sample_interval*frequency, channel) 改为 ((bs*2*neg_number+1), sample_interval*frequency, channel)\n",
    "    neg_ref = net2D(batch[2].reshape(-1, batch[2].shape[2], batch[2].shape[3]).float().unsqueeze(1), output_feature=True).reshape(bs, trials, -1) # (bs, 2*neg_number+1, feature dim)\n",
    "    # print(test_feature.shape, pos_ref.shape, neg_ref.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    # 使用1D组合卷积的情况\n",
    "    bs, trials = batch[2].shape[0], batch[2].shape[1]\n",
    "    # print(batch[0].shape, batch[1].shape, batch[2].shape) \n",
    "    # 计算样本A中的用于比较的特征\n",
    "    test_feature = net(batch[0].float().transpose(1,2), output_feature=True) # (bs, feature dim)\n",
    "    # 计算样本B中的pos参考特征\n",
    "    pos_ref = net(batch[1].float().transpose(1,2), output_feature=True) # (bs, feature dim)\n",
    "    # 计算负向的参考特征\n",
    "    # 此处为了卷积计算，需要先将 (bs, 2*neg_number+1, sample_interval*frequency, channel) 改为 ((bs*2*neg_number+1), sample_interval*frequency, channel)\n",
    "    neg_ref = net(batch[2].reshape(-1, batch[2].shape[2], batch[2].shape[3]).float().transpose(1,2), output_feature=True).reshape(bs, trials, -1) # (bs, 2*neg_number+1, feature dim)\n",
    "    # print(test_feature.shape, pos_ref.shape, neg_ref.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0731, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def contrastive_loss(test_feature, pos_ref, neg_ref):\n",
    "    # 计算 contrastive loss\n",
    "    # 为了方便余弦相似度计算，首先将每一个 feature 标准化，然后整理成方便矩阵乘法的形式\n",
    "    test_feature = F.normalize(test_feature, dim=-1).unsqueeze(2) # bs, feature dim, 1\n",
    "    pos_ref = F.normalize(pos_ref, dim=-1).unsqueeze(1) # bs, 1, feature dim\n",
    "    neg_ref = F.normalize(neg_ref, dim=-1) # bs, 2*ref_trails+1, feature dim\n",
    "    # 计算式（7）分子项：\n",
    "    # pos = torch.bmm(test_feature, pos_ref)\n",
    "    pos = torch.bmm(pos_ref, test_feature)\n",
    "    # print(pos.shape)\n",
    "    # 计算式（7）分母项：\n",
    "    # neg = torch.bmm(test_feature, neg_ref)\n",
    "    neg = torch.bmm(neg_ref, test_feature) # bs, 2*ref_trails+1, 1\n",
    "    # print(neg.shape)\n",
    "    sum_exp_neg = torch.exp(neg).sum(1, keepdim=True) # 先求指数再求和\n",
    "    # 计算论文中式（7）\n",
    "    log_prob = pos - torch.log(sum_exp_neg)\n",
    "    contrast_loss = -log_prob.mean()\n",
    "    return contrast_loss\n",
    "contrastive_loss(test_feature, pos_ref, neg_ref)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4bc46d1d81d35e3f7a6aab9abda1a1c655b5613dc48c5fb7637acc9fa16b17d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
